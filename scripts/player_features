import pandas as pd
import numpy as np
import os
import tempfile
import shutil
import firebase_admin
from firebase_admin import credentials, storage

# -------------------------------
# --- Step 0: Firebase Setup ----
# -------------------------------
cred = credentials.Certificate("/path/to/your/firebase-service-account.json")
firebase_admin.initialize_app(cred, {
    'storageBucket': 'sports-betting-model-fea2f.firebasestorage.app'
})
bucket = storage.bucket()

def download_from_firebase(firebase_path, local_path):
    blob = bucket.blob(firebase_path)
    blob.download_to_filename(local_path)
    print(f"Downloaded {firebase_path} -> {local_path}")

def upload_to_firebase(local_path, firebase_path):
    blob = bucket.blob(firebase_path)
    blob.upload_from_filename(local_path)
    print(f"Uploaded {local_path} -> {firebase_path}")

# -------------------------------
# --- Step 1: Prepare temp paths
# -------------------------------
tmp_dir = tempfile.mkdtemp()
try:
    # Input Firebase paths
    schedules_firebase_path = "nfl/raw_data/nfl_schedules_all_years.parquet"
    weekly_stats_firebase_path = "nfl/raw_data/nfl_weekly_stats_all_years.parquet"
    pbp_firebase_path = "nfl/raw_data/nfl_pbp_all_years.parquet"

    schedules_local = os.path.join(tmp_dir, "nfl_schedules_all_years.parquet")
    weekly_stats_local = os.path.join(tmp_dir, "nfl_weekly_stats_all_years.parquet")
    pbp_local = os.path.join(tmp_dir, "nfl_pbp_all_years.parquet")

    download_from_firebase(schedules_firebase_path, schedules_local)
    download_from_firebase(weekly_stats_firebase_path, weekly_stats_local)
    download_from_firebase(pbp_firebase_path, pbp_local)


# -------------------------------
    # --- Step 2: Load DataFrames ---
    # -------------------------------
    df_schedules_all = pd.read_parquet(schedules_local)
    print(f"Loaded schedules: {df_schedules_all.shape}")
    df_weekly_stats_all = pd.read_parquet(weekly_stats_local)
    print(f"Loaded weekly stats: {df_weekly_stats_all.shape}")
    df_pbp_all = pd.read_parquet(pbp_local)
    print(f"Loaded play-by-play: {df_pbp_all.shape}")


# --- Step 3: Initial Game-Level Feature Engineering ---
# We will primarily use df_schedules_all and df_pbp_all for game-level features.
# df_weekly_stats_all will be used later for player-level features.

df_games_teams = pd.DataFrame() # Initialize an empty DataFrame
if df_schedules_all is not None and not df_schedules_all.empty:
    print("\n--- Starting Game-Level Feature Engineering ---")

    # Ensure gameday is datetime and sort for time-series operations
    df_schedules_all['gameday'] = pd.to_datetime(df_schedules_all['gameday'])
    df_schedules_all = df_schedules_all.sort_values(by=['season', 'week', 'gameday']).reset_index(drop=True)

    # 3.1. Basic Game Outcomes / Target Variables
    # Point Differential (Home Score - Away Score)
    df_schedules_all['score_differential'] = df_schedules_all['home_score'] - df_schedules_all['away_score']
    # Absolute Point Differential (Margin of Victory)
    df_schedules_all['abs_score_differential'] = abs(df_schedules_all['score_differential'])
    # Home Team Win (1 if home wins, 0 if home loses/ties)
    # Note: Ties are rare but can be handled as 0.5 for home_win, or excluded.
    # For now, if result is 0 (tie), home_win will be 0.
    df_schedules_all['home_win'] = (df_schedules_all['score_differential'] > 0).astype(int)
    # Over/Under (1 if total > total_line, 0 if total < total_line, 0.5 if total == total_line)
    df_schedules_all['total_over'] = np.where(df_schedules_all['total'] > df_schedules_all['total_line'], 1,
                                            np.where(df_schedules_all['total'] < df_schedules_all['total_line'], 0, 0.5))

    print("Added basic game outcome features (score_differential, abs_score_differential, home_win, total_over).")

    # 3.2. Team-Specific Game Features (for both home and away teams)
    # We need to transform the schedule data so each row represents a team's perspective in a game.
    # This is crucial for calculating rolling averages correctly.

    # Define common columns that should always be present
    common_game_cols = ['game_id', 'season', 'week', 'gameday', 'score_differential', 'home_win', 'total', 'total_line', 'total_over']

    # Define odds-related columns that might be missing for older years
    # Check for their existence in df_schedules_all
    odds_cols_home_raw = ['home_moneyline', 'spread_line', 'home_spread_odds']
    odds_cols_away_raw = ['away_moneyline', 'spread_line', 'away_spread_odds']

    existing_odds_cols_home = [col for col in odds_cols_home_raw if col in df_schedules_all.columns]
    existing_odds_cols_away = [col for col in odds_cols_away_raw if col in df_schedules_all.columns]

    # Create a DataFrame for home team's perspective
    home_selection_cols = common_game_cols + ['home_team', 'home_score', 'away_team', 'away_score', 'home_rest'] + existing_odds_cols_home
    df_home = df_schedules_all[home_selection_cols].copy()
    df_home.rename(columns={
        'home_team': 'team',
        'home_score': 'team_score',
        'away_team': 'opponent',
        'away_score': 'opponent_score',
        'score_differential': 'team_score_differential', # Positive means team won
        'home_win': 'team_win', # 1 if this team won
        'home_rest': 'team_rest',
        'home_moneyline': 'team_moneyline',
        'spread_line': 'team_spread_line', # Spread from this team's perspective
        'home_spread_odds': 'team_spread_odds'
    }, inplace=True)
    df_home['is_home'] = 1 # Flag for home game

    # Create a DataFrame for away team's perspective
    away_selection_cols = common_game_cols + ['away_team', 'away_score', 'home_team', 'home_score', 'away_rest'] + existing_odds_cols_away
    df_away = df_schedules_all[away_selection_cols].copy()
    df_away.rename(columns={
        'away_team': 'team',
        'away_score': 'team_score',
        'home_team': 'opponent',
        'home_score': 'opponent_score',
        'score_differential': 'opponent_score_differential', # Positive means opponent won (negative for this team)
        'home_win': 'opponent_win', # 1 if opponent won (0 if this team won)
        'away_rest': 'team_rest',
        'away_moneyline': 'team_moneyline',
        'spread_line': 'opponent_spread_line', # Spread from opponent's perspective
        'away_spread_odds': 'team_spread_odds'
    }, inplace=True)

    # Corrected line: Use 'opponent_score_differential' which is already in df_away
    df_away['team_score_differential'] = -df_away['opponent_score_differential']
    df_away['team_win'] = 1 - df_away['opponent_win'] # 1 if this team won (0 if opponent won)
    df_away['is_home'] = 0 # Flag for away game

    # Adjust spread_line for away team: if home team is -X, away team is +X
    # This needs to be done using the *renamed* opponent_spread_line column
    if 'opponent_spread_line' in df_away.columns: # Check if the column exists after renaming
        df_away['team_spread_line'] = -df_away['opponent_spread_line']
    else:
        df_away['team_spread_line'] = np.nan # Or handle as appropriate if spread data is missing

    # Drop the original opponent-perspective columns after transformation
    # 'spread_line' is already renamed, so it shouldn't be dropped here.
    cols_to_drop_away = ['opponent_score_differential', 'opponent_win']
    df_away.drop(columns=[col for col in cols_to_drop_away if col in df_away.columns], inplace=True)


    # Concatenate home and away perspectives
    df_games_teams = pd.concat([df_home, df_away], ignore_index=True)

    # Sort by game_id and then by team to ensure consistent ordering for future merges
    df_games_teams = df_games_teams.sort_values(by=['game_id', 'team']).reset_index(drop=True)

    print(f"Created team-game level DataFrame (df_games_teams). Shape: {df_games_teams.shape}")
    print(df_games_teams.head())


    # 3.3. Rolling Averages for Team Performance (using df_games_teams)
    # This is a crucial step for creating predictive features.
    # We need to calculate these *before* the current game, so we sort by date.

    # Sort data by team and gameday to ensure correct rolling window
    df_games_teams = df_games_teams.sort_values(by=['team', 'gameday']).reset_index(drop=True)

    # Define metrics for rolling averages
    rolling_metrics = ['team_score', 'opponent_score', 'team_score_differential']
    windows = [3, 5, 8] # Rolling window sizes (last 3, 5, 8 games)

    for metric in rolling_metrics:
        for window in windows:
            # Calculate rolling mean, shifting by 1 to avoid data leakage (using previous games only)
            df_games_teams[f'rolling_{metric}_{window}_games'] = df_games_teams.groupby('team')[metric].transform(
                lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()
            )
            # Fill NaN for early games (where there aren't enough previous games) with 0 or a league average
            # For simplicity, let's fill with 0 for now, but league average is better in production
            df_games_teams[f'rolling_{metric}_{window}_games'] = df_games_teams[f'rolling_{metric}_{window}_games'].fillna(0)

    print("Calculated rolling averages for team scores and differentials.")

    # --- 3.4. Advanced Game-Level Features from Play-by-Play Data (df_pbp_all) ---
    if df_pbp_all is not None and not df_pbp_all.empty:
        print("\n--- Adding Advanced Game-Level Features from Play-by-Play Data ---")

        # Ensure 'game_id' is consistent and 'posteam'/'defteam' are present
        if 'game_id' not in df_pbp_all.columns or 'posteam' not in df_pbp_all.columns or 'defteam' not in df_pbp_all.columns:
            print("Skipping advanced PBP features: Missing essential columns in df_pbp_all.")
        else:
            # Red Zone Efficiency (Offense)
            # Plays starting within 20 yards of opponent's endzone
            df_pbp_all['is_redzone_attempt'] = (df_pbp_all['yardline_100'] <= 20) & (df_pbp_all['play_type'].isin(['pass', 'run']))
            # Red zone touchdowns
            df_pbp_all['is_redzone_td'] = df_pbp_all['is_redzone_attempt'] & (df_pbp_all['touchdown'] == 1)

            # Third Down Conversion Rate (Offense)
            df_pbp_all['is_third_down_attempt'] = (df_pbp_all['down'] == 3)
            # FIX: Ensure proper parentheses for boolean operations
            df_pbp_all['is_third_down_conversion'] = df_pbp_all['is_third_down_attempt'] & ((df_pbp_all['first_down_rush'] == 1) | (df_pbp_all['first_down_pass'] == 1) | (df_pbp_all['first_down_penalty'] == 1))

            # Turnover Differential
            df_pbp_all['turnover_committed'] = df_pbp_all['interception'] | df_pbp_all['fumble_lost']
            df_pbp_all['turnover_forced'] = df_pbp_all.groupby('game_id')['turnover_committed'].transform(lambda x: x.shift(1).fillna(0)) # This is a simplification, ideally track by defteam

            # Calculate offensive EPA per play
            # Filter for relevant play types before calculating EPA
            pbp_epa = df_pbp_all[df_pbp_all['play_type'].isin(['pass', 'run'])].copy()
            offensive_epa_per_play = pbp_epa.groupby(['game_id', 'posteam']).agg(
                offensive_epa_per_play=('epa', 'mean')
            ).reset_index()
            offensive_epa_per_play.rename(columns={'posteam': 'team'}, inplace=True)

            # Calculate defensive EPA allowed per play (negative of offensive EPA)
            defensive_epa_per_play = pbp_epa.groupby(['game_id', 'defteam']).agg(
                defensive_epa_per_play_allowed=('epa', 'mean')
            ).reset_index()
            defensive_epa_per_play.rename(columns={'defteam': 'team'}, inplace=True)
            # Defensive EPA allowed should be negative of offensive EPA
            defensive_epa_per_play['defensive_epa_per_play_allowed'] = -defensive_epa_per_play['defensive_epa_per_play_allowed']

            # --- New Features from PBP ---
            # Net Yards Per Play
            # Sum of yards gained by offense, sum of yards allowed by defense, and total plays
            pbp_offense_yards = df_pbp_all.groupby(['game_id', 'posteam']).agg(
                total_offensive_yards=('yards_gained', 'sum'),
                total_offensive_plays=('play_id', 'count') # Count of plays
            ).reset_index()
            pbp_offense_yards.rename(columns={'posteam': 'team'}, inplace=True)

            pbp_defense_yards = df_pbp_all.groupby(['game_id', 'defteam']).agg(
                total_defensive_yards_allowed=('yards_gained', 'sum'),
                total_defensive_plays_faced=('play_id', 'count') # Count of plays faced
            ).reset_index()
            pbp_defense_yards.rename(columns={'defteam': 'team'}, inplace=True)

            # Merge offensive and defensive yardage stats
            pbp_yards_per_play = pd.merge(pbp_offense_yards, pbp_defense_yards, on=['game_id', 'team'], how='left')
            pbp_yards_per_play['net_yards_per_play'] = (pbp_yards_per_play['total_offensive_yards'] - pbp_yards_per_play['total_defensive_yards_allowed']) / (pbp_yards_per_play['total_offensive_plays'] + pbp_yards_per_play['total_defensive_plays_faced'])
            pbp_yards_per_play['net_yards_per_play'] = pbp_yards_per_play['net_yards_per_play'].fillna(0) # Handle division by zero if no plays

            # Penalty Differential
            pbp_penalties = df_pbp_all.groupby(['game_id', 'posteam']).agg(
                penalty_yards_committed=('penalty_yards', 'sum')
            ).reset_index()
            pbp_penalties.rename(columns={'posteam': 'team'}, inplace=True)

            pbp_penalties_forced = df_pbp_all.groupby(['game_id', 'defteam']).agg(
                penalty_yards_forced=('penalty_yards', 'sum')
            ).reset_index()
            pbp_penalties_forced.rename(columns={'defteam': 'team'}, inplace=True)

            pbp_penalty_stats = pd.merge(pbp_penalties, pbp_penalties_forced, on=['game_id', 'team'], how='left')
            pbp_penalty_stats['penalty_yards_committed'] = pbp_penalty_stats['penalty_yards_committed'].fillna(0)
            pbp_penalty_stats['penalty_yards_forced'] = pbp_penalty_stats['penalty_yards_forced'].fillna(0)
            pbp_penalty_stats['penalty_differential'] = pbp_penalty_stats['penalty_yards_forced'] - pbp_penalty_stats['penalty_yards_committed']


            # Explosive Play Rate (Offensive)
            # Define an explosive play (e.g., run > 10 yards, pass > 20 yards)
            df_pbp_all['is_explosive_run'] = (df_pbp_all['play_type'] == 'run') & (df_pbp_all['yards_gained'] >= 10)
            df_pbp_all['is_explosive_pass'] = (df_pbp_all['play_type'] == 'pass') & (df_pbp_all['yards_gained'] >= 20)
            df_pbp_all['is_explosive_play'] = df_pbp_all['is_explosive_run'] | df_pbp_all['is_explosive_pass']

            pbp_explosive_plays = df_pbp_all[df_pbp_all['play_type'].isin(['run', 'pass'])].groupby(['game_id', 'posteam']).agg(
                total_plays=('play_id', 'count'),
                explosive_plays=('is_explosive_play', 'sum')
            ).reset_index()
            pbp_explosive_plays.rename(columns={'posteam': 'team'}, inplace=True)
            pbp_explosive_plays['offensive_explosive_play_rate'] = pbp_explosive_plays['explosive_plays'] / pbp_explosive_plays['total_plays']
            pbp_explosive_plays['offensive_explosive_play_rate'] = pbp_explosive_plays['offensive_explosive_play_rate'].fillna(0)


            # Defensive Explosive Play Rate Allowed
            pbp_explosive_plays_allowed = df_pbp_all[df_pbp_all['play_type'].isin(['run', 'pass'])].groupby(['game_id', 'defteam']).agg(
                total_plays_faced=('play_id', 'count'),
                explosive_plays_allowed=('is_explosive_play', 'sum')
            ).reset_index()
            pbp_explosive_plays_allowed.rename(columns={'defteam': 'team'}, inplace=True)
            pbp_explosive_plays_allowed['defensive_explosive_play_rate_allowed'] = pbp_explosive_plays_allowed['explosive_plays_allowed'] / pbp_explosive_plays_allowed['total_plays_faced']
            pbp_explosive_plays_allowed['defensive_explosive_play_rate_allowed'] = pbp_explosive_plays_allowed['defensive_explosive_play_rate_allowed'].fillna(0)

            # --- New Features: Success Rate, Drive Success Rate, Average Starting Field Position ---
            # Success Rate (Offense) - This does not depend on drive_id, so it can always be calculated
            df_pbp_all['is_success'] = 0
            df_pbp_all.loc[(df_pbp_all['down'] == 1) & (df_pbp_all['yards_gained'] >= 0.4 * df_pbp_all['ydstogo']), 'is_success'] = 1
            df_pbp_all.loc[(df_pbp_all['down'] == 2) & (df_pbp_all['yards_gained'] >= 0.6 * df_pbp_all['ydstogo']), 'is_success'] = 1
            df_pbp_all.loc[(df_pbp_all['down'] >= 3) & (df_pbp_all['first_down'] == 1), 'is_success'] = 1 # A first down on 3rd/4th down is a success

            pbp_success_rate = df_pbp_all[df_pbp_all['play_type'].isin(['pass', 'run'])].groupby(['game_id', 'posteam']).agg(
                total_plays_for_success_rate=('play_id', 'count'),
                successful_plays=('is_success', 'sum')
            ).reset_index()
            pbp_success_rate.rename(columns={'posteam': 'team'}, inplace=True)
            pbp_success_rate['offensive_success_rate'] = pbp_success_rate['successful_plays'] / pbp_success_rate['total_plays_for_success_rate']
            pbp_success_rate['offensive_success_rate'] = pbp_success_rate['offensive_success_rate'].fillna(0)
            print("Calculated offensive_success_rate.")

            # Initialize these DFs as empty; they will be populated only if 'drive_id' exists
            pbp_drive_success_rate = pd.DataFrame()
            pbp_avg_start_field_pos = pd.DataFrame()

            # Drive Success Rate (Offense) and Average Starting Field Position (Offense) - Depend on drive_id
            if 'drive_id' in df_pbp_all.columns:
                df_pbp_all['is_scoring_play'] = df_pbp_all['touchdown'] | (df_pbp_all['field_goal_result'] == 'made')

                scoring_drives = df_pbp_all[df_pbp_all['is_scoring_play'] == 1][['game_id', 'drive_id', 'posteam']].drop_duplicates()
                scoring_drives['is_drive_successful'] = 1

                all_drives = df_pbp_all[['game_id', 'drive_id', 'posteam']].drop_duplicates()
                all_drives.rename(columns={'posteam': 'team'}, inplace=True)

                all_drives = pd.merge(all_drives, scoring_drives, on=['game_id', 'drive_id', 'team'], how='left')
                all_drives['is_drive_successful'] = all_drives['is_drive_successful'].fillna(0)

                pbp_drive_success_rate = all_drives.groupby(['game_id', 'team']).agg(
                    total_drives=('drive_id', 'count'),
                    successful_drives=('is_drive_successful', 'sum')
                ).reset_index()
                pbp_drive_success_rate['offensive_drive_success_rate'] = pbp_drive_success_rate['successful_drives'] / pbp_drive_success_rate['total_drives']
                pbp_drive_success_rate['offensive_drive_success_rate'] = pbp_drive_success_rate['offensive_drive_success_rate'].fillna(0)
                print("Calculated offensive_drive_success_rate.")

                drive_starts = df_pbp_all.groupby(['game_id', 'drive_id', 'posteam']).first().reset_index()
                pbp_avg_start_field_pos = drive_starts.groupby(['game_id', 'posteam']).agg(
                    avg_starting_field_position=('yardline_100', 'mean')
                ).reset_index()
                pbp_avg_start_field_pos.rename(columns={'posteam': 'team'}, inplace=True)
                pbp_avg_start_field_pos['avg_starting_field_position'] = pbp_avg_start_field_pos['avg_starting_field_position'].fillna(0)
                print("Calculated avg_starting_field_position.")
            else:
                print("Skipping Drive Success Rate and Average Starting Field Position: 'drive_id' column not found in play-by-play data.")


            # Aggregate PBP stats per game for each team (existing and new)
            pbp_game_stats = df_pbp_all.groupby(['game_id', 'posteam']).agg(
                redzone_attempts=('is_redzone_attempt', 'sum'),
                redzone_tds=('is_redzone_td', 'sum'),
                third_down_attempts=('is_third_down_attempt', 'sum'),
                third_down_conversions=('is_third_down_conversion', 'sum'),
                turnovers_committed=('turnover_committed', 'sum')
            ).reset_index()
            pbp_game_stats.rename(columns={'posteam': 'team'}, inplace=True)

            # Merge defensive stats (turnovers forced by opponent)
            defensive_turnovers = df_pbp_all.groupby(['game_id', 'defteam']).agg(
                turnovers_forced=('turnover_committed', 'sum')
            ).reset_index()
            defensive_turnovers.rename(columns={'defteam': 'team'}, inplace=True)

            pbp_game_stats = pd.merge(pbp_game_stats, defensive_turnovers, on=['game_id', 'team'], how='left')
            pbp_game_stats['turnovers_forced'] = pbp_game_stats['turnovers_forced'].fillna(0) # Fill NaNs for teams that didn't force turnovers

            # Merge EPA stats into pbp_game_stats
            pbp_game_stats = pd.merge(pbp_game_stats, offensive_epa_per_play, on=['game_id', 'team'], how='left')
            pbp_game_stats = pd.merge(pbp_game_stats, defensive_epa_per_play, on=['game_id', 'team'], how='left')
            # Merge new PBP derived features
            pbp_game_stats = pd.merge(pbp_game_stats, pbp_yards_per_play[['game_id', 'team', 'net_yards_per_play']], on=['game_id', 'team'], how='left')
            pbp_game_stats = pd.merge(pbp_game_stats, pbp_penalty_stats[['game_id', 'team', 'penalty_differential']], on=['game_id', 'team'], how='left')
            pbp_game_stats = pd.merge(pbp_game_stats, pbp_explosive_plays[['game_id', 'team', 'offensive_explosive_play_rate']], on=['game_id', 'team'], how='left')
            pbp_game_stats = pd.merge(pbp_game_stats, pbp_explosive_plays_allowed[['game_id', 'team', 'defensive_explosive_play_rate_allowed']], on=['game_id', 'team'], how='left')

            # Merge the newly added features if they are not empty
            if not pbp_success_rate.empty:
                pbp_game_stats = pd.merge(pbp_game_stats, pbp_success_rate[['game_id', 'team', 'offensive_success_rate']], on=['game_id', 'team'], how='left')
            if not pbp_drive_success_rate.empty:
                pbp_game_stats = pd.merge(pbp_game_stats, pbp_drive_success_rate[['game_id', 'team', 'offensive_drive_success_rate']], on=['game_id', 'team'], how='left')
            if not pbp_avg_start_field_pos.empty:
                pbp_game_stats = pd.merge(pbp_game_stats, pbp_avg_start_field_pos[['game_id', 'team', 'avg_starting_field_position']], on=['game_id', 'team'], how='left')


            # Calculate per-game rates/differentials
            pbp_game_stats['redzone_td_pct'] = pbp_game_stats['redzone_tds'] / pbp_game_stats['redzone_attempts']
            pbp_game_stats['third_down_conv_pct'] = pbp_game_stats['third_down_conversions'] / pbp_game_stats['third_down_attempts']
            pbp_game_stats['turnover_differential'] = pbp_game_stats['turnovers_forced'] - pbp_game_stats['turnovers_committed']

            # Fill NaNs from division by zero in percentages and EPA
            pbp_game_stats['redzone_td_pct'] = pbp_game_stats['redzone_td_pct'].fillna(0)
            pbp_game_stats['third_down_conv_pct'] = pbp_game_stats['third_down_conv_pct'].fillna(0)
            pbp_game_stats['offensive_epa_per_play'] = pbp_game_stats['offensive_epa_per_play'].fillna(0)
            pbp_game_stats['defensive_epa_per_play_allowed'] = pbp_game_stats['defensive_epa_per_play_allowed'].fillna(0)
            pbp_game_stats['net_yards_per_play'] = pbp_game_stats['net_yards_per_play'].fillna(0)
            pbp_game_stats['penalty_differential'] = pbp_game_stats['penalty_differential'].fillna(0)
            pbp_game_stats['offensive_explosive_play_rate'] = pbp_game_stats['offensive_explosive_play_rate'].fillna(0)
            pbp_game_stats['defensive_explosive_play_rate_allowed'] = pbp_game_stats['defensive_explosive_play_rate_allowed'].fillna(0)

            # Fill NaNs for the newly added features if they exist
            if 'offensive_success_rate' in pbp_game_stats.columns:
                pbp_game_stats['offensive_success_rate'] = pbp_game_stats['offensive_success_rate'].fillna(0)
            if 'offensive_drive_success_rate' in pbp_game_stats.columns:
                pbp_game_stats['offensive_drive_success_rate'] = pbp_game_stats['offensive_drive_success_rate'].fillna(0)
            if 'avg_starting_field_position' in pbp_game_stats.columns:
                pbp_game_stats['avg_starting_field_position'] = pbp_game_stats['avg_starting_field_position'].fillna(0)


            # Merge these aggregated stats back into df_games_teams
            # Create a list of columns to merge from pbp_game_stats dynamically
            pbp_cols_to_merge = ['game_id', 'team', 'redzone_td_pct', 'third_down_conv_pct', 'turnover_differential',
                                 'offensive_epa_per_play', 'defensive_epa_per_play_allowed',
                                 'net_yards_per_play', 'penalty_differential', 'offensive_explosive_play_rate',
                                 'defensive_explosive_play_rate_allowed']

            # Add new features to this list if they were calculated and exist in pbp_game_stats
            if 'offensive_success_rate' in pbp_game_stats.columns:
                pbp_cols_to_merge.append('offensive_success_rate')
            if 'offensive_drive_success_rate' in pbp_game_stats.columns:
                pbp_cols_to_merge.append('offensive_drive_success_rate')
            if 'avg_starting_field_position' in pbp_game_stats.columns:
                pbp_cols_to_merge.append('avg_starting_field_position')

            df_games_teams = pd.merge(df_games_teams, pbp_game_stats[pbp_cols_to_merge], on=['game_id', 'team'], how='left')

            # Now calculate rolling averages for these features
            # Dynamically build advanced_rolling_metrics based on what's available in df_games_teams
            advanced_rolling_metrics = [col for col in pbp_cols_to_merge if col not in ['game_id', 'team']] # Exclude merge keys

            for metric in advanced_rolling_metrics:
                for window in windows: # Using same windows as before
                    df_games_teams[f'rolling_{metric}_{window}_games'] = df_games_teams.groupby('team')[metric].transform(
                        lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()
                    )
                    df_games_teams[f'rolling_{metric}_{window}_games'] = df_games_teams[f'rolling_{metric}_{window}_games'].fillna(0) # Fill NaNs for early games

            print("Added rolling advanced PBP features.")
    else:
        print("Play-by-play data not available or empty. Skipping advanced PBP features.")

    print("\nInitial game-level feature engineering complete.")


    # Save the enhanced game-level DataFrame
    game_level_features_local = os.path.join(tmp_dir, "nfl_game_level_features.parquet")
    df_games_teams.to_parquet(game_level_features_local, index=False)
    print(f"\nEnhanced game-level features saved to: {output_game_level_features}")

else:
    print("Schedules data not available or empty. Skipping game-level feature engineering.")


# --- Step 4: Player-Level Feature Engineering (using df_weekly_stats_all) ---
df_player_level_features = pd.DataFrame()  # Initialize an empty DataFrame

if df_weekly_stats_all is not None and not df_weekly_stats_all.empty:
    print("\n--- Starting Player-Level Feature Engineering ---")

    # Ensure data is sorted by player and week for time-series operations
    df_weekly_stats_all = df_weekly_stats_all.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)

    # 4.0 --- Fix missing home/away and game_id reference ---
    if 'is_home' not in df_weekly_stats_all.columns:
        if df_schedules_all is not None and not df_schedules_all.empty:
            # Merge weekly stats to schedules using season, week, and team
            df_weekly_stats_all = df_weekly_stats_all.merge(
                df_schedules_all[['season', 'week', 'home_team', 'away_team', 'game_id']],
                left_on=['season', 'week', 'recent_team'],
                right_on=['season', 'week', 'home_team'],
                how='left'
            )
            # Home/Away flag
            df_weekly_stats_all['is_home'] = (df_weekly_stats_all['recent_team'] == df_weekly_stats_all['home_team']).astype(int)
            # Keep game_id for reference
            df_weekly_stats_all.rename(columns={'game_id':'game_id_ref'}, inplace=True)
            df_weekly_stats_all.drop(columns=['home_team','away_team'], inplace=True)
        else:
            df_weekly_stats_all['is_home'] = np.nan

    # --- Step 4.1 Rolling averages for core player stats ---
    player_rolling_metrics = [
        'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'carries',
        'rushing_yards', 'rushing_tds', 'receptions', 'targets',
        'receiving_yards', 'receiving_tds', 'fantasy_points_ppr'
    ]
    player_windows = [3, 5, 8]

    for metric in player_rolling_metrics:
        for window in player_windows:
            df_weekly_stats_all[f'rolling_{metric}_{window}_weeks'] = df_weekly_stats_all.groupby('player_id')[metric].transform(
                lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()
            ).fillna(0)

    print("Calculated rolling averages for core player statistics.")

    # --- Step 4.2 Advanced Player-Level Features ---
    print("\n--- Adding Advanced Player-Level Features ---")

    # 1️⃣ Opponent Defensive Matchup Ranks (avg fantasy points allowed by opponent to player's position)
    df_opp_defense = df_weekly_stats_all.groupby(['season', 'week', 'opponent_team', 'position']).agg(
        opp_avg_fantasy_allowed=('fantasy_points_ppr', 'mean')
    ).reset_index()

    df_weekly_stats_all = df_weekly_stats_all.merge(
        df_opp_defense,
        on=['season', 'week', 'opponent_team', 'position'],
        how='left'
    )

    # 2️⃣ Player Historical Performance vs Specific Opponent Teams (rolling averages)
    rolling_metrics_vs_opponent = ['fantasy_points_ppr', 'passing_yards', 'rushing_yards', 'receiving_yards']
    for metric in rolling_metrics_vs_opponent:
        for window in player_windows:
            df_weekly_stats_all[f'rolling_{metric}_vs_opponent_{window}_weeks'] = df_weekly_stats_all.groupby(
                ['player_id', 'opponent_team']
            )[metric].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()).fillna(0)

    # 3️⃣ Rolling averages by home/away
    rolling_metrics_home_away = ['fantasy_points_ppr', 'passing_yards', 'rushing_yards', 'receiving_yards']
    for metric in rolling_metrics_home_away:
        for window in player_windows:
            df_weekly_stats_all[f'rolling_{metric}_home_{window}_weeks'] = (
                df_weekly_stats_all.groupby(['player_id', 'is_home'])[metric]
                .transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).mean())
                .fillna(0)
            )

    # 4️⃣ Snap Share / Target Share Rolling
    rolling_usage_cols = ['target_share']
    for col in rolling_usage_cols:
        if col in df_weekly_stats_all.columns:
            for window in player_windows:
                df_weekly_stats_all[f'rolling_{col}_{window}_weeks'] = df_weekly_stats_all.groupby(
                    'player_id'
                )[col].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()).fillna(0)

    # 5️⃣ Team Pace & Run/Pass Ratio from play-by-play
    if df_pbp_all is not None and not df_pbp_all.empty:
        team_plays = df_pbp_all.groupby(['season','week','posteam']).agg(
            plays=('play_id','count'),
            run_plays=('play_type', lambda x: (x=='run').sum()),
            pass_plays=('play_type', lambda x: (x=='pass').sum())
        ).reset_index().rename(columns={'posteam':'team'})
        team_plays['run_pass_ratio'] = team_plays['run_plays'] / team_plays['pass_plays'].replace(0,1)
        team_plays['pace'] = team_plays['plays']

        df_weekly_stats_all = df_weekly_stats_all.merge(
            team_plays[['season','week','team','pace','run_pass_ratio']],
            left_on=['season','week','recent_team'],
            right_on=['season','week','team'],
            how='left'
        ).drop(columns=['team'])

    # 6️⃣ Defensive Coverage Tendencies of Opponent
    if df_pbp_all is not None and not df_pbp_all.empty:
        # Group by opponent and coverage type
        coverage_summary = df_pbp_all.groupby(['season','week','defteam','defense_coverage_type', 'defense_man_zone_type']).agg(
            plays=('play_id','count')
        ).reset_index()
        coverage_pivot = coverage_summary.pivot_table(
            index=['season','week','defteam'],
            columns=['defense_coverage_type', 'defense_man_zone_type'],
            values='plays',
            fill_value=0
        ).reset_index()

        # Flatten multiindex columns
        coverage_pivot.columns = [
            '_'.join([str(c) for c in col if c not in ['', None]])
            if isinstance(col, tuple) else col
            for col in coverage_pivot.columns
        ]
        coverage_cols = [c for c in coverage_pivot.columns if c not in ['season','week','defteam']]
        coverage_pivot[coverage_cols] = coverage_pivot[coverage_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
        coverage_pivot[coverage_cols] = coverage_pivot[coverage_cols].div(coverage_pivot[coverage_cols].sum(axis=1), axis=0)

        df_weekly_stats_all = df_weekly_stats_all.merge(
            coverage_pivot,
            left_on=['season','week','opponent_team'],
            right_on=['season','week','defteam'],
            how='left'
        ).drop(columns=['defteam'])

    # 7️⃣ Player Effectiveness vs Coverage (Receiver, Passer, Rusher)
    if df_pbp_all is not None and not df_pbp_all.empty:
        def add_role_prefix(df, role):
            """Helper: Add role prefix to metric columns before pivot."""
            metric_cols = [c for c in df.columns
                          if c not in ['player_id','season','week','defense_coverage_type','defense_man_zone_type']]
            rename_map = {c: f"{role}_{c}" for c in metric_cols}
            return df.rename(columns=rename_map)

        # ---- RECEIVER vs COVERAGE ----
        receiver_vs_coverage = df_pbp_all.groupby(
            ['receiver_player_id','season','week','defense_coverage_type','defense_man_zone_type']
        ).agg(
            yds_per_target=('yards_gained','mean'),
            catch_rate=('complete_pass','mean'),
            targets=('play_id','count')
        ).reset_index().rename(columns={'receiver_player_id':'player_id'})
        receiver_vs_coverage = add_role_prefix(receiver_vs_coverage, "receiver")
        receiver_vs_coverage['role'] = 'receiver'

        # ---- PASSER vs COVERAGE ----
        passer_vs_coverage = df_pbp_all.groupby(
            ['passer_player_id','season','week','defense_coverage_type','defense_man_zone_type']
        ).agg(
            yds_per_att=('yards_gained','mean'),
            comp_rate=('complete_pass','mean'),
            attempts=('play_id','count'),
            pass_tds=('pass_touchdown','sum'),
            interceptions=('interception','sum')
        ).reset_index().rename(columns={'passer_player_id':'player_id'})
        passer_vs_coverage = add_role_prefix(passer_vs_coverage, "passer")
        passer_vs_coverage['role'] = 'passer'

        # ---- RUSHER vs COVERAGE ----
        rusher_vs_coverage = df_pbp_all.groupby(
            ['rusher_player_id','season','week','defense_coverage_type','defense_man_zone_type']
        ).agg(
            yds_per_carry=('yards_gained','mean'),
            carries=('play_id','count'),
            rush_tds=('rush_touchdown','sum')
        ).reset_index().rename(columns={'rusher_player_id':'player_id'})
        rusher_vs_coverage = add_role_prefix(rusher_vs_coverage, "rusher")
        rusher_vs_coverage['role'] = 'rusher'

        # ---- UNION ALL ----
        player_vs_coverage = pd.concat(
            [receiver_vs_coverage, passer_vs_coverage, rusher_vs_coverage],
            ignore_index=True
        )

        # ---- Pivot wide (single-game) ----
        player_vs_cov_wide = player_vs_coverage.pivot_table(
            index=['player_id','season','week','role'],
            columns=['defense_coverage_type','defense_man_zone_type'],
            values=[c for c in player_vs_coverage.columns
                    if c not in ['player_id','season','week','role','defense_coverage_type','defense_man_zone_type']],
            fill_value=0
        ).reset_index()

        # Flatten
        player_vs_cov_wide.columns = [
            "_".join([str(c) for c in col if c not in ["", None]]).lower()
            if isinstance(col, tuple) else str(col).lower()
            for col in player_vs_cov_wide.columns
        ]

        # Merge weekly stats
        df_weekly_stats_all = df_weekly_stats_all.merge(
            player_vs_cov_wide.drop(columns=['role']),  # role is embedded in colnames
            on=['player_id','season','week'],
            how='left'
        )

        # ---- Rolling windows ----
        # Melt for rolling calc
        coverage_long = player_vs_coverage.melt(
            id_vars=['player_id','season','week','role','defense_coverage_type','defense_man_zone_type'],
            value_vars=[c for c in player_vs_coverage.columns
                        if c not in ['player_id','season','week','role','defense_coverage_type','defense_man_zone_type']],
            var_name='metric',
            value_name='value'
        ).sort_values(['player_id','season','week'])

        # Rolling last 3 games (shift to avoid leakage)
        coverage_long['last3'] = (
            coverage_long.groupby(['player_id','season','role','metric','defense_coverage_type','defense_man_zone_type'])['value']
            .transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean())
        )

        # Season-to-date expanding mean (shifted)
        coverage_long['season_to_date'] = (
            coverage_long.groupby(['player_id','season','role','metric','defense_coverage_type','defense_man_zone_type'])['value']
            .transform(lambda x: x.shift(1).expanding().mean())
        )

        # Pivot wide again
        coverage_roll_wide = coverage_long.melt(
            id_vars=['player_id','season','week','role','metric','defense_coverage_type','defense_man_zone_type'],
            value_vars=['last3','season_to_date'],
            var_name='window',
            value_name='val'
        ).pivot_table(
            index=['player_id','season','week','role'],
            columns=['window','metric','defense_coverage_type','defense_man_zone_type'],
            values='val',
            fill_value=0
        ).reset_index()

        # Flatten
        coverage_roll_wide.columns = [
            "_".join([str(c) for c in col if c not in ["", None]]).lower()
            if isinstance(col, tuple) else str(col).lower()
            for col in coverage_roll_wide.columns
        ]

        # Merge back
        df_weekly_stats_all = df_weekly_stats_all.merge(
            coverage_roll_wide.drop(columns=['role']),
            on=['player_id','season','week'],
            how='left'
        )



    print("Advanced player-level features (opponent defense, pace, run/pass, coverage) added successfully.")

    # --- Step 4.3 Save enhanced player-level DataFrame ---
    player_level_features_local = os.path.join(tmp_dir, "nfl_player_level_features.parquet")
    df_weekly_stats_all.to_parquet(player_level_features_local, index=False)
    print(f"\nEnhanced player-level features saved to: {output_player_level_features}")
    df_player_level_features = df_weekly_stats_all

else:
    print("Weekly stats data not available or empty. Skipping player-level feature engineering.")




# --- Step 5: Merging DataFrames for Game Outcome Modeling and Finalizing Target Variables ---
print("\n--- Starting Merging DataFrames for Game Outcome Modeling ---")

# Load the enhanced game-level features
df_game_level_features = None
df_game_level_features = pd.read_parquet(game_level_features_local)

if df_game_level_features is not None and not df_game_level_features.empty:
    # Separate into home and away perspectives for merging
    df_home_features = df_game_level_features[df_game_level_features['is_home'] == 1].copy()
    df_away_features = df_game_level_features[df_game_level_features['is_home'] == 0].copy()

    # Define columns that are truly game-level and should be used as merge keys
    game_id_cols = ['game_id', 'season', 'week', 'gameday']

    # Define target columns that should be present in the final merged DataFrame
    # These are the original game outcomes from df_schedules_all, but now they are
    # represented by the 'team_score_differential' and 'team_win' from the HOME team's perspective.
    # 'total', 'total_line', 'total_over' are already directly present in df_game_level_features.

    # We need to ensure that the target columns are explicitly selected and potentially renamed
    # from the home_features DataFrame.

    # Columns that will be the final target variables in the merged DataFrame
    final_target_cols = ['total', 'total_line', 'total_over', 'score_differential', 'home_win']

    # Select the columns for df_home_final
    # Start with game_id_cols
    df_home_final = df_home_features[game_id_cols].copy()

    # Add the overall game outcome columns, renaming them from team_perspective if necessary
    if 'team_score_differential' in df_home_features.columns:
        df_home_final['score_differential'] = df_home_features['team_score_differential']
    if 'team_win' in df_home_features.columns:
        df_home_final['home_win'] = df_home_features['team_win']
    if 'total' in df_home_features.columns:
        df_home_final['total'] = df_home_features['total']
    if 'total_line' in df_home_features.columns:
        df_home_final['total_line'] = df_home_features['total_line']
    if 'total_over' in df_home_features.columns:
        df_home_final['total_over'] = df_home_features['total_over']

    # Identify columns that are team-specific features and need prefixing for HOME team
    # These are all columns in df_home_features that are NOT game_id_cols or the original target_cols
    # (before they were transformed into team_score_differential/team_win)
    home_team_specific_feature_cols = [col for col in df_home_features.columns if col not in game_id_cols + ['team_score_differential', 'team_win', 'total', 'total_line', 'total_over']]
    home_feature_mapping = {col: f'home_{col}' for col in home_team_specific_feature_cols}
    df_home_final = pd.concat([df_home_final, df_home_features[home_team_specific_feature_cols].rename(columns=home_feature_mapping)], axis=1)


    # Select columns for away team and rename
    df_away_final = df_away_features[game_id_cols].copy()
    away_team_specific_feature_cols = [col for col in df_away_features.columns if col not in game_id_cols + ['team_score_differential', 'team_win', 'total', 'total_line', 'total_over']]
    away_feature_mapping = {col: f'away_{col}' for col in away_team_specific_feature_cols}
    df_away_final = pd.concat([df_away_final, df_away_features[away_team_specific_feature_cols].rename(columns=away_feature_mapping)], axis=1)


    # Merge the home and away perspectives back into a single game-level DataFrame
    # Merge only on the core game identifiers
    df_final_game_data = pd.merge(
        df_home_final,
        df_away_final,
        on=game_id_cols, # Use only the core game identifiers for merging
        how='inner'
    )

    print(f"\nFinal game-level DataFrame (df_final_game_data) created. Shape: {df_final_game_data.shape}")
    print("Sample of df_final_game_data:")
    print(df_final_game_data[[
        'game_id', 'gameday', 'home_team', 'away_team',
        'home_team_score', 'away_team_score', # These are the raw scores, now prefixed
        'score_differential', 'home_win', 'total_over', # These are the overall game targets
        'home_rolling_team_score_3_games', 'away_rolling_team_score_3_games'
    ]].head())

    # Save the final game-level DataFrame
    final_game_data_local = os.path.join(tmp_dir, "nfl_final_game_data.parquet")
    df_final_game_data.to_parquet(final_game_data_local, index=False)
    print(f"\nFinal game-level data saved to: {output_final_game_data}")

else:
    print("Game-level features data not available or empty. Skipping final game data merging.")

# -------------------------------
    # --- Step 6: Upload Outputs to Firebase ---
    # -------------------------------
    upload_to_firebase(game_level_features_local, "nfl/features/nfl_game_level_features.parquet")
    upload_to_firebase(player_level_features_local, "nfl/features/nfl_player_level_features.parquet")
    upload_to_firebase(final_game_data_local, "nfl/features/nfl_final_game_data.parquet")

finally:
    # Clean up temp files
    shutil.rmtree(tmp_dir)
    print("Temporary local files cleaned up.")

print("\nFeature engineering complete. All outputs uploaded to Firebase successfully.")
